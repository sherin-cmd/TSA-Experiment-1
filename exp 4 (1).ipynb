{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a9a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('simple', 2), ('example', 2), ('test', 1), ('function', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srmmc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def most_common_non_stopwords(text, top_n=50):\n",
    "    # 1. Tokenize the input text into words (using regex to keep only words)\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # 2. Initialize an empty list to store filtered words\n",
    "    filtered_words = []\n",
    "    \n",
    "    # Get the stop words set\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # 3. Iterate through each word to filter\n",
    "    for word in words:\n",
    "        # a. Check if the word is alphanumeric and not a stop word\n",
    "        if word.isalnum() and word not in stop_words:\n",
    "            # b. Add the word to the list of filtered words\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    # 4. Count the occurrences of each word\n",
    "    word_counts = Counter(filtered_words)\n",
    "    \n",
    "    # 5. Get the top N most common words\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    # 6. Return the list of words and their frequencies\n",
    "    return most_common_words\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is a simple example. This example is just a simple test of the function.\"\n",
    "print(most_common_non_stopwords(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b50acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('words', 7), ('word', 6), ('list', 4), ('filtered', 4), ('store', 2), ('50', 2), ('common', 2), ('tokenize', 1), ('input', 1), ('text', 1), ('initialize', 1), ('empty', 1), ('iterate', 1), ('check', 1), ('alphanumeric', 1), ('stop', 1), ('b', 1), ('conditions', 1), ('met', 1), ('add', 1), ('count', 1), ('occurrences', 1), ('get', 1), ('counts', 1), ('return', 1), ('along', 1), ('frequencies', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srmmc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if needed\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def most_common_non_stopwords(text, top_n=50):\n",
    "    # 1. Tokenize the input text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # 2. Initialize an empty list to store filtered words\n",
    "    filtered_words = []\n",
    "    \n",
    "    # Stop words set\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # 3. Iterate through each word to filter\n",
    "    for word in words:\n",
    "        # a. Check if the word is alphanumeric and not a stop word\n",
    "        if word.isalnum() and word not in stop_words:\n",
    "            # b. Add the word to filtered words list\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    # 4. Count the occurrences of each word\n",
    "    word_counts = Counter(filtered_words)\n",
    "    \n",
    "    # 5. Get the top 50 most common words\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    # 6. Return the list of 50 most common words and their frequencies\n",
    "    return most_common_words\n",
    "\n",
    "# Example input text as given in the algorithm\n",
    "input_text = \"\"\"\n",
    "Tokenize the input text into words. Initialize an empty list to store filtered words. \n",
    "Iterate through each word to store filtered words:\n",
    "a. Check if the word is alphanumeric and not a stop word.\n",
    "b. If conditions are met, add the word to the list of filtered words.\n",
    "Count the occurrences of each word in the list of filtered words.\n",
    "Get the 50 most common words from the word counts.\n",
    "Return the list of the 50 most common words along with their frequencies.\n",
    "\"\"\"\n",
    "\n",
    "print(most_common_non_stopwords(input_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeba67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
